apiVersion: maestro/v1alpha1
kind: Agent
metadata:
  name: slack
  labels:
    app: slack-example
    custom_agent: slack_agent
spec:
  model: dummy
  framework: custom
  mode: remote
  description: slack agent
  instructions: post a message to slack

---
apiVersion: maestro/v1alpha1
kind: Agent
metadata:
  name: Paper Finder
  labels:
    app: mas-example 
spec:
  model: llama3.1
  framework: beeai
  mode: remote
  description: "Retrieve IBM related papers from a certain topic in a certain time frame"
  instructions: |
    Input:
          • category (string) # e.g. "quantum-ph"
          • since_days (int)  # e.g. "1" for the last 1 days since today's date.

        Task:
          1. Call the ibm-arXiv tool to search for all papers on `category` published in the last `since_days`. All the functionality is already implemented in the funciton, simply execute the function with the given parameters as the input, and then return the output (which should be titles of research papers) into a list.
          Directly print out the list in the output.
  code: |
    import arxiv
    import feedparser
    from datetime import datetime, timedelta, timezone
    from typing import List, Dict
    from urllib.parse import urlencode

    def find_ibm_papers(
        category: str,
        since_days: int,
    ) -> List[Dict]:
        """
        Search ArXiv in `category`, pre-filter by abstract keywords, then
        post-filter by author affiliation tags—handling URL encoding properly.
        """
      
        ibm_keywords = ["ibm", "watson", "powerai", "ibm research"]

        cutoff = datetime.now(timezone.utc) - timedelta(days=since_days)
        abs_filter = " OR ".join(f'abs:"{kw}"' for kw in ibm_keywords)
        query = f"cat:{category} AND ({abs_filter})"
        params = {
            "search_query": query,
            "start": 0,
            "max_results": 100,
            "sortBy": "submittedDate",
            "sortOrder": "descending",
        }
        base_url = "http://export.arxiv.org/api/query?"
        url = base_url + urlencode(params)

        feed = feedparser.parse(url)
        papers = []

        for entry in feed.entries:
            published = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
            if published < cutoff:
                continue

            abstract = entry.summary.lower()
            keyword_match = any(kw.lower() in abstract for kw in ibm_keywords)

            affs = entry.get("arxiv_affiliation", [])
            affiliation_match = any("ibm" in aff.lower() for aff in affs)

            if not (keyword_match or affiliation_match):
                continue

            papers.append(entry.title)

        return papers
  tools:
    - 'find_ibm_papers'

---
apiVersion: maestro/v1alpha1
kind: Agent
metadata:
  name: get metadata
  labels:
    app: mas-example 
spec:
  model: llama3.1
  framework: beeai
  mode: remote
  description: "Retrieve metadata for a given arxiv paper"
  instructions: |
    The input will be a title to a research paper from arxiv, which we can call `title`. This will be used as a parameter for the function in step 1. 

    Step1:
    Use the get_metadata tool, passing in the given title to retreive the abstract for the paper.  The function call should just be `get_metadata_by_title(title)`. 

    Currently you are using the Thought, Result, and Reason step which is the final output that is generated. However, I want you to stop at the Result step (which should directly just be the output of the function).
    *STRICTLY output the result of the function and nothing else*

    Example output that the user should see:
    {
      "title": inputted title,
      "authors": [
          actual authors retrieved by the function
      ],
      "published": actual date retrieved by the function,
      "abstract": actual abstract retrieved by the function
    }
  code: |
    import arxiv
    from typing import Optional

    def get_metadata_by_title(title: str) -> Optional[str]:
        """
        Given the exact title of an arXiv paper, fetch its abstract.
        Returns None if no match is found.
        """
        client = arxiv.Client()
        search = arxiv.Search(
            query=f'ti:"{title}"',
            max_results=1
        )
        result = next(client.results(search), None)
        if not result:
            return None
        return {
            "title":     result.title,
            "authors":   [a.name for a in result.authors],
            "published": result.published.strftime("%Y-%m-%d"),
            "abstract":  result.summary.strip()
        }
  tools:
    - 'get_metadata_by_title'

---
apiVersion: maestro/v1alpha1
kind: Agent
metadata:
  name: generate summary
  labels:
    app: mas-example 
spec:
  model: llama3.1
  framework: beeai
  mode: remote
  description: "Generate summary using metadata"
  instructions: |
    You are a paper‐summary agent. You will receive exactly one JSON object as input. **Do not** attempt to fetch or validate anything—use only these fields:

    {
      "title":    <string>,
      "authors":  [<string>, …],
      "published":<string (YYYY-MM-DD)>,
      "abstract": <string>
    }

    Your job is to output **only** a two-paragraph plain-text summary in this format:

    1. **Header line**  
      {title}, by {Author1, Author2, …} (Published: {published})

    2. **Expanded summary**  
      - **Para 1:** Restate and extend the abstract in clear, concise language, emphasizing main contributions and results.  
      - **Para 2:** Explain any key terms, methods, or concepts so that a general technical reader can follow.

    **Constraints:**  
    - Do **not** output JSON or attempt to look up anything.  
    - Do **not** include extra sections.  
    - Keep the full summary ~150–200 words.

    **Example input:**
    {
      "title": "Bounds in Wasserstein Distance for Locally Stationary Functional Time Series",
      "authors": ["Johannes Schmidt-Hieber"],
      "published": "2021-01-22",
      "abstract": "We derive bounds on the Wasserstein distance…"
    }

    **Example output:**

    Bounds in Wasserstein Distance for Locally Stationary Functional Time Series, by Johannes Schmidt-Hieber (Published: 2021-01-22)

    This paper derives new upper and lower bounds on the Wasserstein distance between locally stationary functional time series and their mean-field limits. Building on a novel concentration inequality for Gaussian fields under mild smoothness conditions, the author shows that the distance decays at rate O(n^{–α}) as sample size n grows. Numerical experiments confirm the theoretical rates and illustrate applications to high-dimensional time series forecasting.

    To help non-specialists:  
    - **Wasserstein distance:** a metric for comparing probability distributions, used here to quantify approximation errors.  
    - **Locally stationary process:** a time series whose statistical properties evolve slowly, allowing analysis in small windows.  
    - **Concentration inequality:** a probabilistic bound on how much a random variable deviates from its expectation, applied to functionals of Gaussian processes.

  tools: 
    - 'LLM'